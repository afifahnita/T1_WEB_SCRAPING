{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMfuakqLLtVwTy8COImMehN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afifahnita/T1_WEB_SCRAPING/blob/main/Untitled13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYPDXu1q4YJd",
        "outputId": "ef07c9de-370e-4eb8-89a1-45a89c9da296"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Total artikel terkumpul: 348\n",
            "➡️ Data berhasil disimpan ke tempo_articles.csv, tempo_articles.xlsx, tempo_articles.json\n",
            "    category                                              title  \\\n",
            "0   Nasional  Dua Warga Australia Didakwa Jual Senjata ke TP...   \n",
            "1   Nasional  Istana Pasikan Kekosongan Dua Kursi Menteri Ta...   \n",
            "2   Nasional  UMKM Binaan Pertamina Berhasil Berdayakan Peta...   \n",
            "3   Nasional  Komisi X akan Cek Langsung Distribusi Papan Di...   \n",
            "4   Nasional          Mengapa Revisi UU Pemilu Perlu Dilakukan?   \n",
            "5   Nasional             Bagaimana Seharusnya BAIS TNI Bekerja?   \n",
            "6   Nasional  Respons TNI Atas Pembentukan TGPF Demonstrasi ...   \n",
            "7   Nasional  Istana Setuju Pembangunan Alun-alun Demokrasi ...   \n",
            "8   Nasional  Jakarta Mengalami 1.195 Kebakaran hingga Septe...   \n",
            "9   Nasional  Kementerian Pendidikan Dasar Hanya Dapat Tamba...   \n",
            "10  Nasional  Anggota DPR: Publik Berhak Melihat Data Capres...   \n",
            "11  Nasional  Menteri Abdul Mu'ti: Yang Benar Program Intera...   \n",
            "12  Nasional  Hutama Karya Salurkan Bantuan Bagi Sektor Pend...   \n",
            "13  Nasional  Politikus PDIP: Penutupan Akses Dokumen Capres...   \n",
            "14  Nasional  Rahayu Saraswati Bantah Mundur dari DPR karena...   \n",
            "15  Nasional  Penjelasan KPU soal Dokumen Persyaratan Capres...   \n",
            "16  Nasional  Menteri Kehutanan Bentuk Tim Percepatan Peneta...   \n",
            "17  Nasional  DPR Tak Akan Panggil Lagi TNI soal Kehadiran B...   \n",
            "18  Nasional  Politikus Gerindra Anggap Tak Ada yang Salah s...   \n",
            "19  Nasional  Anggota DPR Bicara Alasan RUU Perampasan Aset ...   \n",
            "\n",
            "                                                 link  \\\n",
            "0   https://nasional.tempo.co/read/2049113/dua-war...   \n",
            "1   https://nasional.tempo.co/read/2049107/istana-...   \n",
            "2   https://nasional.tempo.co/read/2049103/umkm-bi...   \n",
            "3   https://nasional.tempo.co/read/2049102/komisi-...   \n",
            "4   https://nasional.tempo.co/read/2049099/mengapa...   \n",
            "5   https://nasional.tempo.co/read/2049093/bagaima...   \n",
            "6   https://nasional.tempo.co/read/2049090/respons...   \n",
            "7   https://nasional.tempo.co/read/2049088/istana-...   \n",
            "8   https://nasional.tempo.co/read/2049072/jakarta...   \n",
            "9   https://nasional.tempo.co/read/2049070/kemente...   \n",
            "10  https://nasional.tempo.co/read/2049068/anggota...   \n",
            "11  https://nasional.tempo.co/read/2049066/menteri...   \n",
            "12  https://nasional.tempo.co/read/2049064/hutama-...   \n",
            "13  https://nasional.tempo.co/read/2049061/politik...   \n",
            "14  https://nasional.tempo.co/read/2049050/rahayu-...   \n",
            "15  https://nasional.tempo.co/read/2049040/penjela...   \n",
            "16  https://nasional.tempo.co/read/2049038/menteri...   \n",
            "17  https://nasional.tempo.co/read/2049036/dpr-tak...   \n",
            "18  https://nasional.tempo.co/read/2049033/politik...   \n",
            "19  https://nasional.tempo.co/read/2049026/anggota...   \n",
            "\n",
            "                               date  \\\n",
            "0   Mon, 15 Sep 2025 17:07:22 +0700   \n",
            "1   Mon, 15 Sep 2025 16:56:23 +0700   \n",
            "2   Mon, 15 Sep 2025 16:51:26 +0700   \n",
            "3   Mon, 15 Sep 2025 16:42:48 +0700   \n",
            "4   Mon, 15 Sep 2025 16:32:41 +0700   \n",
            "5   Mon, 15 Sep 2025 16:11:42 +0700   \n",
            "6   Mon, 15 Sep 2025 16:06:33 +0700   \n",
            "7   Mon, 15 Sep 2025 15:48:13 +0700   \n",
            "8   Mon, 15 Sep 2025 15:02:36 +0700   \n",
            "9   Mon, 15 Sep 2025 14:59:00 +0700   \n",
            "10  Mon, 15 Sep 2025 14:51:00 +0700   \n",
            "11  Mon, 15 Sep 2025 14:43:41 +0700   \n",
            "12  Mon, 15 Sep 2025 14:42:43 +0700   \n",
            "13  Mon, 15 Sep 2025 14:32:03 +0700   \n",
            "14  Mon, 15 Sep 2025 13:54:00 +0700   \n",
            "15  Mon, 15 Sep 2025 13:11:00 +0700   \n",
            "16  Mon, 15 Sep 2025 13:04:28 +0700   \n",
            "17  Mon, 15 Sep 2025 13:01:00 +0700   \n",
            "18  Mon, 15 Sep 2025 12:49:22 +0700   \n",
            "19  Mon, 15 Sep 2025 12:31:30 +0700   \n",
            "\n",
            "                                              summary  \n",
            "0   Dua warga Australia yang didakwa telah memperd...  \n",
            "1   Sampai saat ini Presiden Prabowo belum menunju...  \n",
            "2   UMKM ini bahkan mampu memberdayakan hampir ser...  \n",
            "3   Komisi X belum mengetahui seperti apa bentuk p...  \n",
            "4   Koalisi Masyarakat Sipil menyampaikan sejumlah...  \n",
            "5   Kehadiran BAIS TNI dalam demonstrasi akhir Agu...  \n",
            "6   Brigadir Jenderal Freddy Ardianzah mengatakan ...  \n",
            "7   Usulan pembangunan alun-alun demokrasi disampa...  \n",
            "8   Setidaknya 267 dari 1.195 kebakaran diatasi ol...  \n",
            "9   Sebagian besar fraksi di Komisi X menyampaikan...  \n",
            "10  KPU sebelumnya mengeluarkan keputusan yang men...  \n",
            "11  Menteri Pendidikan Abdul Mu'ti mengatakan prog...  \n",
            "12  Hutama Karya berupaya menghadirkan manfaat nya...  \n",
            "13  Keputusan KPU merahasiakan sebagian data pasan...  \n",
            "14  Kursi Menpora di Kabinet Prabowo saat ini masi...  \n",
            "15  Ada 16 dokumen persyaratan capres-cawapres yan...  \n",
            "16  Raja Juli mengatakan, sejak 2016-2024 sudah se...  \n",
            "17  DPR sudah mendapat klarifikasi TNI soal keterl...  \n",
            "18  Dia menilai penayangan video itu merupakan ino...  \n",
            "19  Dia menegaskan perlunya keseimbangan antara su...  \n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Daftar kategori RSS Tempo\n",
        "rss_feeds = {\n",
        "    \"Nasional\": \"https://rss.tempo.co/nasional\",\n",
        "    \"Bisnis\": \"https://rss.tempo.co/bisnis\",\n",
        "    \"Metro\": \"https://rss.tempo.co/metro\",\n",
        "    \"Dunia\": \"https://rss.tempo.co/dunia\",\n",
        "    \"Olahraga\": \"https://rss.tempo.co/olahraga\",\n",
        "    \"Teknologi\": \"https://rss.tempo.co/tekno\",\n",
        "    \"Seleb\": \"https://rss.tempo.co/seleb\",\n",
        "    \"Otomotif\": \"https://rss.tempo.co/otomotif\",\n",
        "}\n",
        "\n",
        "articles = []\n",
        "\n",
        "# Loop semua kategori\n",
        "for category, url in rss_feeds.items():\n",
        "    res = requests.get(url, timeout=10)\n",
        "    soup = BeautifulSoup(res.content, \"xml\")\n",
        "\n",
        "    for item in soup.find_all(\"item\"):\n",
        "        title = item.title.get_text(strip=True) if item.title else None\n",
        "        link = item.link.get_text(strip=True) if item.link else None\n",
        "        pub_date = item.pubDate.get_text(strip=True) if item.pubDate else None\n",
        "        description = item.description.get_text(strip=True) if item.description else None\n",
        "\n",
        "        articles.append({\n",
        "            \"category\": category,\n",
        "            \"title\": title,\n",
        "            \"link\": link,\n",
        "            \"date\": pub_date,\n",
        "            \"summary\": description\n",
        "        })\n",
        "\n",
        "# Konversi ke DataFrame\n",
        "df = pd.DataFrame(articles)\n",
        "\n",
        "# Simpan ke CSV\n",
        "df.to_csv(\"tempo_articles.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "# Simpan ke Excel (XLSX)\n",
        "df.to_excel(\"tempo_articles.xlsx\", index=False)\n",
        "\n",
        "# Simpan ke JSON\n",
        "with open(\"tempo_articles.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(articles, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"✅ Total artikel terkumpul: {len(df)}\")\n",
        "print(\"➡️ Data berhasil disimpan ke tempo_articles.csv, tempo_articles.xlsx, tempo_articles.json\")\n",
        "\n",
        "# Preview 20 artikel teratas\n",
        "print(df.head(20))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import json\n",
        "import time\n",
        "\n",
        "BASE_URL = \"https://www.cnnindonesia.com\"\n",
        "\n",
        "\n",
        "def get_article_links(limit=10):\n",
        "    \"\"\"Ambil tautan artikel dari halaman utama CNN Indonesia\"\"\"\n",
        "    r = requests.get(BASE_URL, timeout=10)\n",
        "    r.raise_for_status()\n",
        "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "\n",
        "    links = []\n",
        "    for a in soup.select(\"article a\"):\n",
        "        href = a.get(\"href\")\n",
        "        if href and href.startswith(\"https://www.cnnindonesia.com\"):\n",
        "            if href not in links:\n",
        "                links.append(href)\n",
        "        if len(links) >= limit:\n",
        "            break\n",
        "    return links\n",
        "\n",
        "\n",
        "def scrape_article(url):\n",
        "    \"\"\"Scrape detail artikel: judul, konten, metadata\"\"\"\n",
        "    try:\n",
        "        r = requests.get(url, timeout=10)\n",
        "        r.raise_for_status()\n",
        "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "\n",
        "        title = soup.find(\"h1\", class_=\"title\").get_text(strip=True) if soup.find(\"h1\", class_=\"title\") else None\n",
        "        content = \" \".join([p.get_text(strip=True) for p in soup.select(\".detail_text p\")])\n",
        "        author = soup.find(\"div\", class_=\"author\")\n",
        "        author = author.get_text(strip=True) if author else None\n",
        "        date = soup.find(\"div\", class_=\"date\").get_text(strip=True) if soup.find(\"div\", class_=\"date\") else None\n",
        "        tags = [tag.get_text(strip=True) for tag in soup.select(\".tag a\")]\n",
        "\n",
        "        return {\n",
        "            \"url\": url,\n",
        "            \"title\": title,\n",
        "            \"author\": author,\n",
        "            \"date\": date,\n",
        "            \"content\": content,\n",
        "            \"tags\": tags,\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Gagal scrape {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Mengambil link artikel dari CNN Indonesia...\")\n",
        "    article_links = get_article_links(limit=20)\n",
        "    print(f\"Ditemukan {len(article_links)} link artikel.\")\n",
        "\n",
        "    data = []\n",
        "    for link in article_links:\n",
        "        artikel = scrape_article(link)\n",
        "        if artikel:\n",
        "            data.append(artikel)\n",
        "        time.sleep(1)  # delay biar ga dianggap bot\n",
        "\n",
        "    # Simpan ke JSON\n",
        "    with open(\"cnn_articles.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    # Simpan ke CSV\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv(\"cnn_articles.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "    # Simpan ke XLSX\n",
        "    df.to_excel(\"cnn_articles.xlsx\", index=False)\n",
        "\n",
        "    print(\"Scraping selesai! Data disimpan ke cnn_articles.json, cnn_articles.csv, cnn_articles.xlsx\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Z5iz2wq4mvC",
        "outputId": "6811861c-794f-43d1-9d2a-8a0786dd5e7c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mengambil link artikel dari CNN Indonesia...\n",
            "Ditemukan 20 link artikel.\n",
            "Scraping selesai! Data disimpan ke cnn_articles.json, cnn_articles.csv, cnn_articles.xlsx\n"
          ]
        }
      ]
    }
  ]
}